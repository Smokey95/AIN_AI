{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-05-09T11:38:43.476534Z","iopub.status.busy":"2023-05-09T11:38:43.475986Z","iopub.status.idle":"2023-05-09T11:38:43.484996Z","shell.execute_reply":"2023-05-09T11:38:43.483796Z","shell.execute_reply.started":"2023-05-09T11:38:43.476491Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import math\n","\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score # calculate accuracy\n","\n","from sklearn.linear_model import LinearRegression\n","from sklearn.linear_model import LogisticRegression\n","\n","import time\n","from datetime import datetime\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["If running the code above there should be three lines which shows were the data is store"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["***\n","\n","## Import data\n","\n","Next the required training and test data will be imported"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-09T11:38:48.554601Z","iopub.status.busy":"2023-05-09T11:38:48.554179Z","iopub.status.idle":"2023-05-09T11:38:48.576625Z","shell.execute_reply":"2023-05-09T11:38:48.575380Z","shell.execute_reply.started":"2023-05-09T11:38:48.554570Z"},"trusted":true},"outputs":[],"source":["train_data = pd.read_csv(\"data/train.csv\")\n","train_data.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-09T11:38:52.800316Z","iopub.status.busy":"2023-05-09T11:38:52.799392Z","iopub.status.idle":"2023-05-09T11:38:52.819411Z","shell.execute_reply":"2023-05-09T11:38:52.818227Z","shell.execute_reply.started":"2023-05-09T11:38:52.800277Z"},"trusted":true},"outputs":[],"source":["test_data = pd.read_csv(\"data/test.csv\")\n","test_data.head()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["***\n","\n","## Explore a pattern\n","\n","In this part we should get in touch with our first data analysis pattern for this competition."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-09T11:40:06.181611Z","iopub.status.busy":"2023-05-09T11:40:06.181238Z","iopub.status.idle":"2023-05-09T11:40:06.192291Z","shell.execute_reply":"2023-05-09T11:40:06.191244Z","shell.execute_reply.started":"2023-05-09T11:40:06.181582Z"},"trusted":true},"outputs":[],"source":["women_data = train_data.loc[train_data.Sex == 'female'][\"Survived\"]\n","men_data   = train_data.loc[train_data.Sex == 'male'][\"Survived\"]\n"," \n","rate_women = sum(women_data)/len(women_data) * 100\n","rate_men   = sum(men_data)/len(men_data) * 100\n","\n","p_woman    = (len(women_data)*100)/len(train_data)\n","p_men      = (len(men_data)*100)/len(train_data)\n","\n","print(\"%-Woman | %-Men\")\n","print(\" \", math.ceil(p_woman), \"   |  \", math.ceil(p_men))\n","print(\"Women survived:\", rate_women)\n","print(\"Men   survived:\", rate_men)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["As you will see there were more mens than women's on the titanic. But the women's had a higher survival rate than the mens."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["To take this further and relate it to our exercise from the lecture, the same approach is taken but with the ticket class"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-09T11:40:11.241853Z","iopub.status.busy":"2023-05-09T11:40:11.241404Z","iopub.status.idle":"2023-05-09T11:40:11.256787Z","shell.execute_reply":"2023-05-09T11:40:11.255087Z","shell.execute_reply.started":"2023-05-09T11:40:11.241815Z"},"trusted":true},"outputs":[],"source":["min_class = min(train_data.Pclass)\n","max_class = max(train_data.Pclass)\n","print(\"Min Class:\", min_class)\n","print(\"Max Class:\", max_class)\n","\n","class_1_data = train_data.loc[train_data.Pclass == 1][\"Survived\"]\n","class_2_data = train_data.loc[train_data.Pclass == 2][\"Survived\"]\n","class_3_data = train_data.loc[train_data.Pclass == 3][\"Survived\"]\n","\n","rate_1_class = sum(class_1_data)/len(class_1_data) * 100\n","rate_2_class = sum(class_2_data)/len(class_2_data) * 100\n","rate_3_class = sum(class_3_data)/len(class_3_data) * 100\n","\n","print(\"1 Class survived:\", math.ceil(rate_1_class), \"%\")\n","print(\"2 Class survived:\", math.ceil(rate_2_class), \"%\")\n","print(\"3 Class survived:\", math.ceil(rate_3_class), \"%\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-09T11:40:21.491292Z","iopub.status.busy":"2023-05-09T11:40:21.490889Z","iopub.status.idle":"2023-05-09T11:40:21.584668Z","shell.execute_reply":"2023-05-09T11:40:21.583600Z","shell.execute_reply.started":"2023-05-09T11:40:21.491257Z"},"trusted":true},"outputs":[],"source":["id_class_data = pd.crosstab(train_data.PassengerId, train_data.Pclass)\n","pd.crosstab(train_data.PassengerId, train_data.Pclass)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["*** \n","\n","## Linear Regression\n","\n","Ignore this part, thats just a working zone..."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-08T17:08:07.492387Z","iopub.status.busy":"2023-05-08T17:08:07.491937Z","iopub.status.idle":"2023-05-08T17:08:07.529519Z","shell.execute_reply":"2023-05-08T17:08:07.528275Z","shell.execute_reply.started":"2023-05-08T17:08:07.492337Z"},"trusted":true},"outputs":[],"source":["x = pd.crosstab(train_data.PassengerId, train_data.Pclass)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-09T06:56:39.007762Z","iopub.status.busy":"2023-05-09T06:56:39.007373Z","iopub.status.idle":"2023-05-09T06:56:39.211375Z","shell.execute_reply":"2023-05-09T06:56:39.210318Z","shell.execute_reply.started":"2023-05-09T06:56:39.007732Z"},"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","from sklearn.linear_model import LinearRegression\n","\n","# Create random data with numpy, and plot it with matplotlib:\n","x = np.array(train_data.Pclass)\n","#print(len(x))\n","y = np.array(train_data.Survived)\n","#print(len(y))\n","\n","x_test = np.array(test_data.Pclass)\n","\n","# Create a linear regression model based the positioning of the data and Intercept, and predict a Best Fit:\n","model = LinearRegression(fit_intercept=True)\n","#print(x[:, np.newaxis])\n","model.fit(x[:, np.newaxis], y)\n","\n","xfit = np.linspace(1, 3, len(train_data))\n","xfit_test = np.linspace(1, 3, len(test_data))\n","\n","train_prediction = model.predict(xfit[:, np.newaxis])\n","prediction = model.predict(xfit[:, np.newaxis])\n","\n","# Plot the estimated linear regression line with matplotlib:\n","plt.scatter(x, y)\n","plt.plot(xfit, train_prediction);\n","plt.show()\n","#print(xfit)\n","#acc = accuracy_score(y, train_prediction)\n","#print(\"Accuracy: ~\", math.ceil(acc * 100), \"%\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["***\n","\n","## Logistic Regression\n","\n","Like requested we should do the same using Logistic Regression\n","\n","Also just using the `Pclass` of the training data to predict if a passenger will survivey leads to a accuracy of ~68%.\n","Uploading the data to **kaggles** submission will show that either the *Random Forest Model* and the *Logistic Regression* will match with a score of **0.67224**.\n","\n","To determine the accuracy the training data will further be splitted into test and training data sets. Therefore the `train_test_split` function is used to split the data-set into 80/20 parts.\n","\n","Running the code below more than once will show, that the accuracy \n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-09T13:03:22.387322Z","iopub.status.busy":"2023-05-09T13:03:22.386623Z","iopub.status.idle":"2023-05-09T13:03:22.411943Z","shell.execute_reply":"2023-05-09T13:03:22.410601Z","shell.execute_reply.started":"2023-05-09T13:03:22.387276Z"},"trusted":true},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","x, x_tt = train_test_split(train_data, test_size=0.2) #Split data into a trainining set = x and a test training set = x_tt to calculate accuracy later\n","\n","model = LogisticRegression() #Setup the model\n","\n","y      = x[\"Survived\"]      #specify the y-value to train the model\n","y_tt   = x_tt[\"Survived\"]   #do the same for the training test data set\n","\n","features = [\"Pclass\"] #specify the features using a list to play with the parameters later\n","x      = pd.get_dummies(x[features]) #define the training input data\n","x_tt   = pd.get_dummies(x_tt[features])  #defines the training test data to calculate accuracy\n","\n","x_test = pd.get_dummies(test_data[features]) #define the real test data input\n","\n","model.fit(x, y) #train the model with the training data\n","\n","predictions_train = model.predict(x_tt) #prediction using the test training data set\n","\n","predictions       = model.predict(x_test) #prediction using the real test data provided by kaggle\n","\n","acc = accuracy_score(y_tt, predictions_train)\n","print(\"Accuracy: ~\", math.ceil(acc * 100), \"%\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Logistic Regression Expand\n","\n","Adding more features like the age requires a data manipulation cause there are `NaN` values in.\n","\n","Running the code below and see the age of Passenger 6 (Mr. James) is missing...\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-09T12:02:08.080783Z","iopub.status.busy":"2023-05-09T12:02:08.080363Z","iopub.status.idle":"2023-05-09T12:02:08.104315Z","shell.execute_reply":"2023-05-09T12:02:08.103065Z","shell.execute_reply.started":"2023-05-09T12:02:08.080749Z"},"trusted":true},"outputs":[],"source":["train_data = pd.read_csv(\"data/train.csv\")\n","train_data.head(6)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["This will be fixed with adding a age to all `NaN` age values. We will take the median as age for passengers where age is not set.\n","\n","Running the code bellow will show, that the missing value is now filled."]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2023-05-09T12:02:19.832498Z","iopub.status.busy":"2023-05-09T12:02:19.831448Z","iopub.status.idle":"2023-05-09T12:02:19.850799Z","shell.execute_reply":"2023-05-09T12:02:19.849545Z","shell.execute_reply.started":"2023-05-09T12:02:19.832458Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"source":["train_data[\"Age\"].fillna(train_data[\"Age\"].median(skipna=True), inplace=True)\n","train_data.head(6)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Also it is recommonded to convert string values to numerical values which can be done using `pandas` `get_dummies` function. Play the two code parts below to the the diffrence"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-09T13:19:23.732621Z","iopub.status.busy":"2023-05-09T13:19:23.732241Z","iopub.status.idle":"2023-05-09T13:19:23.741532Z","shell.execute_reply":"2023-05-09T13:19:23.740409Z","shell.execute_reply.started":"2023-05-09T13:19:23.732591Z"},"trusted":true},"outputs":[],"source":["train_data[\"Sex\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-09T13:19:29.051819Z","iopub.status.busy":"2023-05-09T13:19:29.051437Z","iopub.status.idle":"2023-05-09T13:19:29.063713Z","shell.execute_reply":"2023-05-09T13:19:29.062724Z","shell.execute_reply.started":"2023-05-09T13:19:29.051789Z"},"trusted":true},"outputs":[],"source":["pd.get_dummies(train_data[\"Sex\"])"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["The code bellow does all the covered points from above and generates a `predictions` which can be exported and uploades to **kaggle** like definded at the end of this notebook"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-09T13:18:44.711753Z","iopub.status.busy":"2023-05-09T13:18:44.711355Z","iopub.status.idle":"2023-05-09T13:18:44.758093Z","shell.execute_reply":"2023-05-09T13:18:44.757003Z","shell.execute_reply.started":"2023-05-09T13:18:44.711721Z"},"trusted":true},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","train_data = pd.read_csv(\"data/train.csv\")\n","test_data = pd.read_csv(\"data/test.csv\")\n","\n","train_data[\"Age\"].fillna(train_data[\"Age\"].median(skipna=True), inplace=True) #Fill missing age in train data\n","test_data[\"Age\"].fillna(test_data[\"Age\"].median(skipna=True), inplace=True)   #Fill missing age in test data\n","\n","x, x_tt = train_test_split(train_data, test_size=0.2) #Split data into a trainining set = x and a test training set = x_tt to calculate accuracy later\n","\n","model = LogisticRegression() #Setup the model\n","\n","y      = x[\"Survived\"]      #specify the y-value to train the model\n","y_tt   = x_tt[\"Survived\"]   #do the same for the training test data set\n","\n","features = [\"Pclass\", \"Age\", \"Sex\"] #specify the features using a list to play with the parameters later\n","x      = pd.get_dummies(x[features]) #define the training input data\n","x_tt   = pd.get_dummies(x_tt[features])  #defines the training test data to calculate accuracy\n","\n","x_test = pd.get_dummies(test_data[features]) #define the real test data input\n","\n","model.fit(x, y) #train the model with the training data\n","\n","predictions_train = model.predict(x_tt) #prediction using the test training data set\n","\n","predictions       = model.predict(x_test) #prediction using the real test data provided by kaggle\n","\n","acc = accuracy_score(y_tt, predictions_train)\n","print(\"Accuracy: ~\", math.ceil(acc * 100), \"%\")\n","\n","x_test.head(6)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["***\n","\n","## Random forest model\n","\n","This model was given by the tutorial. To determine the accuracy the `accuracy_score` function was used comparing the train_data with its own prediction.\n","\n","Using features like described in the tutorial `features = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]` there should be a accuracy from round about 82%.\n","\n","Using only `features = [\"Pclass\"]` will \"only\" lead to a accuracy of 68 %"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-09T07:17:33.931628Z","iopub.status.busy":"2023-05-09T07:17:33.931243Z","iopub.status.idle":"2023-05-09T07:17:34.148750Z","shell.execute_reply":"2023-05-09T07:17:34.147499Z","shell.execute_reply.started":"2023-05-09T07:17:33.931597Z"},"trusted":true},"outputs":[],"source":["y = train_data[\"Survived\"]\n","\n","features = [\"Pclass\"]\n","\n","X = pd.get_dummies(train_data[features])\n","X_test = pd.get_dummies(test_data[features])\n","\n","model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\n","model.fit(X, y)\n","predictions = model.predict(X_test)\n","train_prediction = model.predict(X)\n","\n","acc = accuracy_score(y, train_prediction)\n","print(\"Accuracy: ~\", math.ceil(acc * 100), \"%\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Random forest expand\n","\n","The Code part bellow will expand the previous treated ML model the random forest. Therefore it covers the requirements of the exercise (2f)."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-09T13:13:19.506703Z","iopub.status.busy":"2023-05-09T13:13:19.506326Z","iopub.status.idle":"2023-05-09T13:13:19.761612Z","shell.execute_reply":"2023-05-09T13:13:19.760378Z","shell.execute_reply.started":"2023-05-09T13:13:19.506675Z"},"trusted":true},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","train_data = pd.read_csv(\"data/train.csv\")\n","test_data = pd.read_csv(\"data/test.csv\")\n","\n","train_data[\"Age\"].fillna(train_data[\"Age\"].median(skipna=True), inplace=True) #Fill missing age in train data\n","test_data[\"Age\"].fillna(test_data[\"Age\"].median(skipna=True), inplace=True)   #Fill missing age in test data\n","\n","x, x_tt = train_test_split(train_data, test_size=0.2) #Split data into a trainining set = x and a test training set = x_tt to calculate accuracy later\n","\n","model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1) #Setup the model\n","\n","y      = x[\"Survived\"]      #specify the y-value to train the model\n","y_tt   = x_tt[\"Survived\"]   #do the same for the training test data set\n","\n","features = [\"Pclass\", \"Age\", \"Sex\", \"SibSp\", \"Parch\"] #specify the features using a list to play with the parameters later\n","x      = pd.get_dummies(x[features]) #define the training input data\n","x_tt   = pd.get_dummies(x_tt[features])  #defines the training test data to calculate accuracy\n","\n","x_test = pd.get_dummies(test_data[features]) #define the real test data input\n","\n","model.fit(x, y) #train the model with the training data\n","\n","predictions_train = model.predict(x_tt) #prediction using the test training data set\n","\n","predictions       = model.predict(x_test) #prediction using the real test data provided by kaggle\n","\n","acc = accuracy_score(y_tt, predictions_train)\n","print(\"Accuracy: ~\", math.ceil(acc * 100), \"%\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["It may would be a idea to add the cabin to the features but as many values are missing and the cabin number is not a ordinal value it would be difficult to use it. Anyway it would be possible to get a correlation between the between the pure presence of a cabin and the survival rate."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["*** \n","\n","## Export submission\n","\n","This part is needed to export the calculated `prediction` as a `.csv` file"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-09T13:38:11.193014Z","iopub.status.busy":"2023-05-09T13:38:11.192603Z","iopub.status.idle":"2023-05-09T13:38:11.204605Z","shell.execute_reply":"2023-05-09T13:38:11.203274Z","shell.execute_reply.started":"2023-05-09T13:38:11.192977Z"},"trusted":true},"outputs":[],"source":["import os\n","\n","timestamp = time.time()\n","timestamp = datetime.fromtimestamp(timestamp).strftime(\"%H_%M_%S\")\n","print(timestamp)\n","\n","predictions #Enhält die Predictions 0 für Tod 1 für Survived\n","output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\n","\n","filename = 'my_submission_' + timestamp + '.csv'\n","fileDir = os.path.join(\"export\", filename)\n","\n","output.to_csv(fileDir, index=False)\n","print(\"Your submission was successfully saved!\")\n","print(fileDir)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.7"}},"nbformat":4,"nbformat_minor":4}
