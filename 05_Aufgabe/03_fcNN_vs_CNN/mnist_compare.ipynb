{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST digit classification: Convolutional Neural Network (CNN) v.s. fully connected Neural Network (fcNN)\n",
    "\n",
    "***\n",
    "\n",
    "**Goal** In this notebook, we will compare the performance of a fully connected neural network (fcNN) and a convolutional neural network (CNN) on the MNIST dataset. We will see that the CNN performs better than the fcNN.\n",
    "\n",
    "**Dataset**: We will work with the MNIST dataset which contains 60'000 28x28 pixel greyscale images of digits and want to classify them into the right label (0-9).\n",
    "\n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation and Imports\n",
    "\n",
    "A pre requirement for this notebook is the installation of tensorflow 2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "if (not tf.__version__.startswith('2')): #Checking if tf 2.0 is installed\n",
    "    print('Please install tensorflow 2.0 to run this notebook')\n",
    "print('Tensorflow version: ',tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('default')\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Convolution2D, MaxPooling2D, Flatten , Activation\n",
    "from tensorflow.keras.utils import to_categorical \n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data\n",
    "\n",
    "We will use the MNIST dataset which is available in the tensorflow datasets package. The dataset is already split into a training and test set and can be imported as seen in the second column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# separate x_train in X_train and X_val, same for y_train\n",
    "X_train=x_train[0:50000] / 255 #divide by 255 so that they are in range 0 to 1\n",
    "Y_train=keras.utils.to_categorical(y_train[0:50000],10) # one-hot encoding\n",
    "\n",
    "X_val=x_train[50000:60000] / 255\n",
    "Y_val=keras.utils.to_categorical(y_train[50000:60000],10)\n",
    "\n",
    "X_test=x_test / 255\n",
    "Y_test=keras.utils.to_categorical(y_test,10)\n",
    "\n",
    "del x_train, y_train, x_test, y_test\n",
    "\n",
    "X_train=np.reshape(X_train, (X_train.shape[0],28,28,1))\n",
    "X_val=np.reshape(X_val, (X_val.shape[0],28,28,1))\n",
    "X_test=np.reshape(X_test, (X_test.shape[0],28,28,1))\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_val.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize the data we will use the code below to show the first 10 images of the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the 4 first mnist images before shuffling the pixels\n",
    "plt.figure(figsize=(12,12))\n",
    "for i in range(0,2):\n",
    "    for j in range(0, 5):\n",
    "        plt.subplot(5,5,(i*10+j+1))\n",
    "        plt.imshow((X_train[i*10+j,:,:,0]),cmap=\"gray\")\n",
    "        plt.title('true label: '+np.str(np.argmax(Y_train,axis=1)[i*10+j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for fcNN - we need a vector as input\n",
    "X_train_flat = X_train.reshape([X_train.shape[0], 784])\n",
    "X_val_flat = X_val.reshape([X_val.shape[0], 784])\n",
    "X_test_flat = X_test.reshape([X_test.shape[0], 784])\n",
    "\n",
    "# check the shape\n",
    "print(X_train_flat.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_val_flat.shape)\n",
    "print(Y_val.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fcNN 1: Default fcNN (sigmoid only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define fcNN with 2 hidden layers\n",
    "model_fcNN = Sequential()\n",
    "\n",
    "model_fcNN.add(Dense(100, batch_input_shape=(None, 784)))\n",
    "model_fcNN.add(Activation('sigmoid'))\n",
    "model_fcNN.add(Dense(50))\n",
    "model_fcNN.add(Activation('sigmoid'))\n",
    "model_fcNN.add(Dense(10))\n",
    "model_fcNN.add(Activation('softmax'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN 1: Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn = Sequential()\n",
    "\n",
    "model_cnn.add(Convolution2D(32, (3, 3), padding = 'valid', input_shape=(28, 28, 1)))\n",
    "model_cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_cnn.add(Convolution2D(64, (3, 3), padding = 'valid'))\n",
    "model_cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model_cnn.add(Flatten())\n",
    "model_cnn.add(Dense(10))\n",
    "model_cnn.add(Activation('softmax'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model and intitialize weights\n",
    "model_fcNN.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "# compile model and intitialize weights\n",
    "model_cnn.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fcNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tain the fcNN and CNN models with the same parameters and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "history_fcNN=model_fcNN.fit(X_train_flat, Y_train, \n",
    "                            batch_size=128, \n",
    "                            epochs=10,\n",
    "                            verbose=2, \n",
    "                            validation_data=(X_val_flat, Y_val)\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "history_cnn=model_cnn.fit(X_train, Y_train, \n",
    "                  batch_size=128, \n",
    "                  epochs=10,\n",
    "                  verbose=2, \n",
    "                  validation_data=(X_val, Y_val)\n",
    "                 )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the results will show that the CNN performs better than the fcNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the development of the accuracy and loss from fcNN and CNN during training\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,2,(1))\n",
    "plt.plot(history_fcNN.history['accuracy'],linestyle='-.')\n",
    "plt.plot(history_fcNN.history['val_accuracy'])\n",
    "plt.plot(history_cnn.history['accuracy'],linestyle='-.')\n",
    "plt.plot(history_cnn.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_fcNN', 'valid_fcNN', 'train_CNN', 'valid_CNN'], loc='lower right')\n",
    "plt.subplot(1,2,(2))\n",
    "plt.plot(history_fcNN.history['loss'],linestyle='-.')\n",
    "plt.plot(history_fcNN.history['val_loss'])\n",
    "plt.plot(history_cnn.history['loss'],linestyle='-.')\n",
    "plt.plot(history_cnn.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_fcNN', 'valid_fcNN', 'train_CNN', 'valid_CNN'], loc='upper right')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fcNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_fcNN=model_fcNN.predict(X_test_flat)\n",
    "print(confusion_matrix(np.argmax(Y_test,axis=1),np.argmax(pred_fcNN,axis=1)))\n",
    "acc_fc_orig = np.sum(np.argmax(Y_test,axis=1)==np.argmax(pred_fcNN,axis=1))/len(pred_fcNN)\n",
    "print(\"Acc_fc_orig_flat = \" , acc_fc_orig)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cnn=model_cnn.predict(X_test)\n",
    "print(confusion_matrix(np.argmax(Y_test,axis=1),np.argmax(pred_cnn,axis=1)))\n",
    "acc_fc_orig = np.sum(np.argmax(Y_test,axis=1)==np.argmax(pred_cnn,axis=1))/len(pred_cnn)\n",
    "print(\"Acc_fc_orig_flat = \" , acc_fc_orig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
