{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST digit classification with a Convolutional Neural Network (CNN)\n",
    "\n",
    "***\n",
    "\n",
    "**Goal** In this notebook, we will train a CNN to classify handwritten digits from the MNIST dataset. We will use the Keras API with the TensorFlow backend.\n",
    "\n",
    "**Dataset**: We will work with the MNIST dataset which contains 60'000 28x28 pixel greyscale images of digits and want to classify them into the right label (0-9).\n",
    "\n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation and Imports\n",
    "\n",
    "A pre requirement for this notebook is the installation of tensorflow 2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "if (not tf.__version__.startswith('2')): #Checking if tf 2.0 is installed\n",
    "    print('Please install tensorflow 2.0 to run this notebook')\n",
    "print('Tensorflow version: ',tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('default')\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Convolution2D, MaxPooling2D, Flatten , Activation\n",
    "from tensorflow.keras.utils import to_categorical \n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# separate x_train in X_train and X_val, same for y_train\n",
    "X_train=x_train[0:50000] / 255 #divide by 255 so that they are in range 0 to 1\n",
    "Y_train=keras.utils.to_categorical(y_train[0:50000],10) # one-hot encoding\n",
    "\n",
    "X_val=x_train[50000:60000] / 255\n",
    "Y_val=keras.utils.to_categorical(y_train[50000:60000],10)\n",
    "\n",
    "X_test=x_test / 255\n",
    "Y_test=keras.utils.to_categorical(y_test,10)\n",
    "\n",
    "del x_train, y_train, x_test, y_test\n",
    "\n",
    "X_train=np.reshape(X_train, (X_train.shape[0],28,28,1))\n",
    "X_val=np.reshape(X_val, (X_val.shape[0],28,28,1))\n",
    "X_test=np.reshape(X_test, (X_test.shape[0],28,28,1))\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_val.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize the data we will use the code below to show the first 10 images of the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the 4 first mnist images before shuffling the pixels\n",
    "plt.figure(figsize=(12,12))\n",
    "for i in range(0,2):\n",
    "    for j in range(0, 5):\n",
    "        plt.subplot(5,5,(i*10+j+1))\n",
    "        plt.imshow((X_train[i*10+j,:,:,0]),cmap=\"gray\")\n",
    "        plt.title('true label: '+np.str(np.argmax(Y_train,axis=1)[i*10+j]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the following code will create a sequential model with the layers like described in the hw5 task. This will lead to extremely bad results (~12% accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(32, (3, 3), padding = 'valid', input_shape=(28, 28, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Convolution2D(64, (3, 3), padding = 'valid'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding a `softmax` activation function to the last layer will lead to a better result (~98% accuracy). This is because the softmax function will normalize the output of the last layer to a probability distribution???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(32, (3, 3), padding = 'valid', input_shape=(28, 28, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Convolution2D(64, (3, 3), padding = 'valid'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model and intitialize weights\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize model along with number of model weights\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "history=model.fit(X_train, Y_train, \n",
    "                  batch_size=128, \n",
    "                  epochs=10,\n",
    "                  verbose=2, \n",
    "                  validation_data=(X_val, Y_val)\n",
    "                 )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of the Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation: Accuracy and Loss Diagram\n",
    "\n",
    "To evaluate the performance of the network we will plot the accuracy and loss diagram. The accuracy is the percentage of correctly classified images and the loss is the error of the network. The loss should decrease over time and the accuracy should increase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the development of the accuracy and loss during training\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,2,(1))\n",
    "plt.plot(history.history['accuracy'],linestyle='-.')\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='lower right')\n",
    "plt.subplot(1,2,(2))\n",
    "plt.plot(history.history['loss'],linestyle='-.')\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='upper right')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation: Confusion Matrix\n",
    "\n",
    "The confusion matrix is a good way to visualize the performance of the network. It shows how many images were classified correctly and how many were classified incorrectly. The confusion matrix is a square matrix with the number of classes as the dimension. The diagonal of the matrix shows the number of correctly classified images. The off-diagonal elements show the number of incorrectly classified images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=model.predict(X_test)\n",
    "print(confusion_matrix(np.argmax(Y_test,axis=1),np.argmax(pred,axis=1)))\n",
    "acc_fc_orig = np.sum(np.argmax(Y_test,axis=1)==np.argmax(pred,axis=1))/len(pred)\n",
    "print(\"Acc_fc_orig_flat = \" , acc_fc_orig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
