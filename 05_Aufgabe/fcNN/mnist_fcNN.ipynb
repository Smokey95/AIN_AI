{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST digit classification with a fully connected network (fcNN)\n",
    "\n",
    "*** \n",
    "\n",
    "**Goal**: In this notebook we will use a fully connected networks (fcNN) in a classification task for the MNIST images\n",
    "\n",
    "**Dataset**: We will work with the MNIST dataset which contains 60'000 28x28 pixel greyscale images of digits and want to classify them into the right label (0-9).\n",
    "\n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pre requirement for this notebook is the installation of tensorflow 2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "if (not tf.__version__.startswith('2')): #Checking if tf 2.0 is installed\n",
    "    print('Please install tensorflow 2.0 to run this notebook')\n",
    "print('Tensorflow version: ',tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('default')\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Convolution2D, MaxPooling2D, Flatten , Activation\n",
    "from tensorflow.keras.utils import to_categorical \n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# separate x_train in X_train and X_val, same for y_train\n",
    "X_train=x_train[0:50000] / 255 #divide by 255 so that they are in range 0 to 1\n",
    "Y_train=keras.utils.to_categorical(y_train[0:50000],10) # one-hot encoding\n",
    "\n",
    "X_val=x_train[50000:60000] / 255\n",
    "Y_val=keras.utils.to_categorical(y_train[50000:60000],10)\n",
    "\n",
    "X_test=x_test / 255\n",
    "Y_test=keras.utils.to_categorical(y_test,10)\n",
    "\n",
    "del x_train, y_train, x_test, y_test\n",
    "\n",
    "X_train=np.reshape(X_train, (X_train.shape[0],28,28,1))\n",
    "X_val=np.reshape(X_val, (X_val.shape[0],28,28,1))\n",
    "X_test=np.reshape(X_test, (X_test.shape[0],28,28,1))\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_val.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the 4 first mnist images before shuffling the pixels\n",
    "plt.figure(figsize=(12,12))\n",
    "for i in range(0,6):\n",
    "    plt.subplot(1,6,(i+1))\n",
    "    plt.imshow((X_train[i,:,:,0]),cmap=\"gray\")\n",
    "    plt.title('true label: '+np.str(np.argmax(Y_train,axis=1)[i]))\n",
    "    #plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for fcNN - we need a vector as input\n",
    "X_train_flat = X_train.reshape([X_train.shape[0], 784])\n",
    "X_val_flat = X_val.reshape([X_val.shape[0], 784])\n",
    "X_test_flat = X_test.reshape([X_test.shape[0], 784])\n",
    "\n",
    "# check the shape\n",
    "print(X_train_flat.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_val_flat.shape)\n",
    "print(Y_val.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fcNN 1: Default fcNN (sigmoid only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define fcNN with 2 hidden layers\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(100, batch_input_shape=(None, 784)))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(50))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fcNN 2: fcNN with relu activation\n",
    "\n",
    "Running the same with relu activation function instead of sigmoid will not increase the accuracy. The reason is that the network is not deep enough to benefit from the relu activation function but also expanding it will not increase the accuracy significantly.\n",
    "\n",
    "More interesting is the fact that the relu activation function tends to overfit the training data. This is due to the fact that the relu function is not bounded and therefore the output of the neurons can be very large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(100, batch_input_shape=(None, 784)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(50))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(100, batch_input_shape=(None, 784)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(90))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(80))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(70))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(60))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(50))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(40))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(30))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(20))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fcNN 1: fcNN with 5 hidden layers (sigmoid only)\n",
    "\n",
    "As you will see when running, adding more layers does not necessarily improve the performance of the network. In fact, the performance of the network is worse than the default network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(100, batch_input_shape=(None, 784)))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(75))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(50))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(20))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(100, batch_input_shape=(None, 784)))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(50))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model and intitialize weights\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize model along with number of model weights\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "history=model.fit(X_train_flat, Y_train, \n",
    "                  batch_size=128, \n",
    "                  epochs=10,\n",
    "                  verbose=2, \n",
    "                  validation_data=(X_val_flat, Y_val)\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the development of the accuracy and loss during training\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,2,(1))\n",
    "plt.plot(history.history['accuracy'],linestyle='-.')\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='lower right')\n",
    "plt.subplot(1,2,(2))\n",
    "plt.plot(history.history['loss'],linestyle='-.')\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=model.predict(X_test_flat)\n",
    "print(confusion_matrix(np.argmax(Y_test,axis=1),np.argmax(pred,axis=1)))\n",
    "acc_fc_orig = np.sum(np.argmax(Y_test,axis=1)==np.argmax(pred,axis=1))/len(pred)\n",
    "print(\"Acc_fc_orig_flat = \" , acc_fc_orig)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " > **Exercise**: Try to improve the fcNN by adding more hidden layers and/or changing the activation function from \"sigmoid\" to \"relu\". What do you observe? can you improve the performace on the testset?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
